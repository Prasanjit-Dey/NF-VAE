{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ge8zaa46Gug",
        "outputId": "55fcc5a1-3954-4f6e-957c-f771311dc822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8wGoR_Qh9xs1",
        "outputId": "e62665fe-35de-4c06-d8db-aca9b582a9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b1bb559-1320-43a1-9dc1-809c319bfb1d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8b1bb559-1320-43a1-9dc1-809c319bfb1d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving combined_matrix.csv to combined_matrix.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "npeEbAh39dCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_combined_matrix = pd.read_csv(\"combined_matrix.csv\")"
      ],
      "metadata": {
        "id": "BswMznDyBg2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_combined_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "crrHaHC7BsD_",
        "outputId": "d347adba-d49e-453c-d78d-9d18c762162e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   parameter_location_id  ...  2021-01-09T12:00:00+08:00\n",
              "0                co_6168  ...                      500.0\n",
              "1               no2_6168  ...                       29.0\n",
              "2                o3_6168  ...                       53.0\n",
              "3              pm10_6168  ...                       36.0\n",
              "4              pm25_6168  ...                       18.0\n",
              "5               so2_6168  ...                        8.0\n",
              "6                co_6169  ...                      400.0\n",
              "7               no2_6169  ...                       19.0\n",
              "8                o3_6169  ...                       56.0\n",
              "9              pm10_6169  ...                       32.0\n",
              "10             pm25_6169  ...                       17.0\n",
              "11              so2_6169  ...                        8.0\n",
              "12               co_6167  ...                      500.0\n",
              "13              no2_6167  ...                       23.0\n",
              "14               o3_6167  ...                       62.0\n",
              "15             pm10_6167  ...                       47.0\n",
              "16             pm25_6167  ...                       22.0\n",
              "17              so2_6167  ...                       10.0\n",
              "18               co_6218  ...                      600.0\n",
              "19              no2_6218  ...                       18.0\n",
              "20               o3_6218  ...                       70.0\n",
              "21             pm10_6218  ...                       71.0\n",
              "22             pm25_6218  ...                       21.0\n",
              "23              so2_6218  ...                        6.0\n",
              "24               co_6274  ...                      700.0\n",
              "25              no2_6274  ...                       31.0\n",
              "26               o3_6274  ...                       61.0\n",
              "27             pm10_6274  ...                      108.0\n",
              "28             pm25_6274  ...                       43.0\n",
              "29              so2_6274  ...                       15.0\n",
              "30               co_6273  ...                      800.0\n",
              "31              no2_6273  ...                       37.0\n",
              "32               o3_6273  ...                       61.0\n",
              "33             pm10_6273  ...                       98.0\n",
              "34             pm25_6273  ...                       52.0\n",
              "35              so2_6273  ...                       13.0\n",
              "\n",
              "[36 rows x 25942 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c728cac9-f910-4f1c-9922-90d2c7f788cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parameter_location_id</th>\n",
              "      <th>2019-10-28T02:00:00+08:00</th>\n",
              "      <th>2018-05-28T12:00:00+08:00</th>\n",
              "      <th>2018-02-23T17:00:00+08:00</th>\n",
              "      <th>2018-03-25T14:00:00+08:00</th>\n",
              "      <th>2019-11-14T11:00:00+08:00</th>\n",
              "      <th>2021-06-01T17:00:00+08:00</th>\n",
              "      <th>2018-09-09T12:00:00+08:00</th>\n",
              "      <th>2018-12-04T01:00:00+08:00</th>\n",
              "      <th>2019-05-22T20:00:00+08:00</th>\n",
              "      <th>2020-05-07T23:00:00+08:00</th>\n",
              "      <th>2018-01-11T05:00:00+08:00</th>\n",
              "      <th>2019-08-21T12:00:00+08:00</th>\n",
              "      <th>2019-01-10T09:00:00+08:00</th>\n",
              "      <th>2019-01-15T15:00:00+08:00</th>\n",
              "      <th>2020-12-09T09:00:00+08:00</th>\n",
              "      <th>2020-04-08T13:00:00+08:00</th>\n",
              "      <th>2018-11-16T17:00:00+08:00</th>\n",
              "      <th>2020-02-17T06:00:00+08:00</th>\n",
              "      <th>2018-01-15T21:00:00+08:00</th>\n",
              "      <th>2018-12-30T04:00:00+08:00</th>\n",
              "      <th>2019-11-12T09:00:00+08:00</th>\n",
              "      <th>2021-06-11T05:00:00+08:00</th>\n",
              "      <th>2019-11-09T00:00:00+08:00</th>\n",
              "      <th>2020-08-05T04:00:00+08:00</th>\n",
              "      <th>2019-12-11T15:00:00+08:00</th>\n",
              "      <th>2019-08-29T19:00:00+08:00</th>\n",
              "      <th>2018-03-21T13:00:00+08:00</th>\n",
              "      <th>2019-11-26T18:00:00+08:00</th>\n",
              "      <th>2018-06-30T16:00:00+08:00</th>\n",
              "      <th>2021-02-02T17:00:00+08:00</th>\n",
              "      <th>2019-08-03T07:00:00+08:00</th>\n",
              "      <th>2019-04-25T20:00:00+08:00</th>\n",
              "      <th>2019-04-03T12:00:00+08:00</th>\n",
              "      <th>2019-12-29T18:00:00+08:00</th>\n",
              "      <th>2021-01-17T23:00:00+08:00</th>\n",
              "      <th>2020-05-28T00:00:00+08:00</th>\n",
              "      <th>2019-02-12T05:00:00+08:00</th>\n",
              "      <th>2021-04-22T14:00:00+08:00</th>\n",
              "      <th>2019-12-12T13:00:00+08:00</th>\n",
              "      <th>2020-10-26T07:00:00+08:00</th>\n",
              "      <th>2019-08-21T05:00:00+08:00</th>\n",
              "      <th>2019-06-07T21:00:00+08:00</th>\n",
              "      <th>2019-08-17T14:00:00+08:00</th>\n",
              "      <th>2018-05-21T21:00:00+08:00</th>\n",
              "      <th>2019-03-15T15:00:00+08:00</th>\n",
              "      <th>2021-05-07T05:00:00+08:00</th>\n",
              "      <th>2018-02-13T12:00:00+08:00</th>\n",
              "      <th>2020-04-03T06:00:00+08:00</th>\n",
              "      <th>2018-01-23T22:00:00+08:00</th>\n",
              "      <th>...</th>\n",
              "      <th>2018-05-29T19:00:00+08:00</th>\n",
              "      <th>2019-03-19T03:00:00+08:00</th>\n",
              "      <th>2020-07-27T13:00:00+08:00</th>\n",
              "      <th>2018-08-01T09:00:00+08:00</th>\n",
              "      <th>2019-10-13T19:00:00+08:00</th>\n",
              "      <th>2020-10-10T14:00:00+08:00</th>\n",
              "      <th>2021-07-05T04:00:00+08:00</th>\n",
              "      <th>2021-05-11T23:00:00+08:00</th>\n",
              "      <th>2021-05-15T12:00:00+08:00</th>\n",
              "      <th>2019-04-17T04:00:00+08:00</th>\n",
              "      <th>2018-12-01T19:00:00+08:00</th>\n",
              "      <th>2021-05-15T06:00:00+08:00</th>\n",
              "      <th>2020-11-02T00:00:00+08:00</th>\n",
              "      <th>2019-01-14T00:00:00+08:00</th>\n",
              "      <th>2020-02-05T13:00:00+08:00</th>\n",
              "      <th>2021-07-13T18:00:00+08:00</th>\n",
              "      <th>2020-07-10T16:00:00+08:00</th>\n",
              "      <th>2020-03-19T10:00:00+08:00</th>\n",
              "      <th>2020-01-26T20:00:00+08:00</th>\n",
              "      <th>2020-11-11T22:00:00+08:00</th>\n",
              "      <th>2020-04-06T13:00:00+08:00</th>\n",
              "      <th>2020-02-21T13:00:00+08:00</th>\n",
              "      <th>2020-06-22T04:00:00+08:00</th>\n",
              "      <th>2018-11-26T01:00:00+08:00</th>\n",
              "      <th>2020-09-04T00:00:00+08:00</th>\n",
              "      <th>2019-05-20T10:00:00+08:00</th>\n",
              "      <th>2019-06-21T22:00:00+08:00</th>\n",
              "      <th>2019-07-05T17:00:00+08:00</th>\n",
              "      <th>2021-03-06T01:00:00+08:00</th>\n",
              "      <th>2021-04-24T02:00:00+08:00</th>\n",
              "      <th>2020-10-16T11:00:00+08:00</th>\n",
              "      <th>2019-11-13T17:00:00+08:00</th>\n",
              "      <th>2021-06-15T23:00:00+08:00</th>\n",
              "      <th>2020-02-17T16:00:00+08:00</th>\n",
              "      <th>2020-05-26T09:00:00+08:00</th>\n",
              "      <th>2019-03-24T19:00:00+08:00</th>\n",
              "      <th>2021-01-25T17:00:00+08:00</th>\n",
              "      <th>2021-02-05T11:00:00+08:00</th>\n",
              "      <th>2019-11-26T06:00:00+08:00</th>\n",
              "      <th>2018-08-09T00:00:00+08:00</th>\n",
              "      <th>2019-08-13T15:00:00+08:00</th>\n",
              "      <th>2020-12-07T18:00:00+08:00</th>\n",
              "      <th>2021-01-15T20:00:00+08:00</th>\n",
              "      <th>2021-03-24T13:00:00+08:00</th>\n",
              "      <th>2018-08-17T02:00:00+08:00</th>\n",
              "      <th>2020-02-08T22:00:00+08:00</th>\n",
              "      <th>2019-04-18T07:00:00+08:00</th>\n",
              "      <th>2020-12-28T06:00:00+08:00</th>\n",
              "      <th>2020-04-14T11:00:00+08:00</th>\n",
              "      <th>2021-01-09T12:00:00+08:00</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>co_6168</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>769.0</td>\n",
              "      <td>680.0</td>\n",
              "      <td>796.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>363.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>2300.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>3070.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>559.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>603.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>...</td>\n",
              "      <td>846.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>491.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>752.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no2_6168</td>\n",
              "      <td>73.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>...</td>\n",
              "      <td>78.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>o3_6168</td>\n",
              "      <td>49.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>62.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pm10_6168</td>\n",
              "      <td>141.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pm25_6168</td>\n",
              "      <td>80.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>...</td>\n",
              "      <td>71.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>so2_6168</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>co_6169</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>905.0</td>\n",
              "      <td>630.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>699.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>2300.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1380.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>784.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1058.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>744.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1206.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1192.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>942.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>931.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>596.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>no2_6169</td>\n",
              "      <td>61.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>...</td>\n",
              "      <td>96.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>o3_6169</td>\n",
              "      <td>52.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>56.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pm10_6169</td>\n",
              "      <td>105.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>...</td>\n",
              "      <td>193.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>pm25_6169</td>\n",
              "      <td>59.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>so2_6169</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>co_6167</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>951.0</td>\n",
              "      <td>596.0</td>\n",
              "      <td>933.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>2300.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>870.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>2600.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>2278.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>896.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1063.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>635.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1126.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>887.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>696.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>568.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>no2_6167</td>\n",
              "      <td>69.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>...</td>\n",
              "      <td>78.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>o3_6167</td>\n",
              "      <td>76.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>59.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>pm10_6167</td>\n",
              "      <td>113.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>194.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>pm25_6167</td>\n",
              "      <td>72.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>...</td>\n",
              "      <td>96.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>so2_6167</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>co_6218</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>674.0</td>\n",
              "      <td>539.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1844.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>736.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>342.0</td>\n",
              "      <td>...</td>\n",
              "      <td>809.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>539.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>no2_6218</td>\n",
              "      <td>42.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>o3_6218</td>\n",
              "      <td>62.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>...</td>\n",
              "      <td>145.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>pm10_6218</td>\n",
              "      <td>118.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>146.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>pm25_6218</td>\n",
              "      <td>66.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>...</td>\n",
              "      <td>82.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>so2_6218</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>co_6274</td>\n",
              "      <td>700.0</td>\n",
              "      <td>474.0</td>\n",
              "      <td>746.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1520.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>480.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>671.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>599.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>710.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>581.0</td>\n",
              "      <td>...</td>\n",
              "      <td>641.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1183.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>786.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>no2_6274</td>\n",
              "      <td>44.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>o3_6274</td>\n",
              "      <td>109.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>261.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>...</td>\n",
              "      <td>108.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>pm10_6274</td>\n",
              "      <td>112.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>...</td>\n",
              "      <td>152.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>108.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>pm25_6274</td>\n",
              "      <td>60.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>...</td>\n",
              "      <td>56.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>so2_6274</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>co_6273</td>\n",
              "      <td>600.0</td>\n",
              "      <td>730.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>1096.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>706.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>794.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>705.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>618.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>612.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>589.0</td>\n",
              "      <td>...</td>\n",
              "      <td>785.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1131.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>837.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>790.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>no2_6273</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>...</td>\n",
              "      <td>36.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>o3_6273</td>\n",
              "      <td>109.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>120.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>pm10_6273</td>\n",
              "      <td>122.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>...</td>\n",
              "      <td>136.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>345.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>pm25_6273</td>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>48.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>so2_6273</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>411.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36 rows × 25942 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c728cac9-f910-4f1c-9922-90d2c7f788cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c728cac9-f910-4f1c-9922-90d2c7f788cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c728cac9-f910-4f1c-9922-90d2c7f788cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a4a56ae-ed64-40c0-b044-63607a2e4939\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a4a56ae-ed64-40c0-b044-63607a2e4939')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a4a56ae-ed64-40c0-b044-63607a2e4939 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c0edbc27-251f-4825-90d0-3671c9c009ad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sorted_combined_matrix')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c0edbc27-251f-4825-90d0-3671c9c009ad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sorted_combined_matrix');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_combined_matrix = sorted_combined_matrix.set_index('parameter_location_id')\n",
        "\n",
        "sorted_combined_matrix_T =sorted_combined_matrix.T\n",
        "sorted_combined_matrix_T.replace(to_replace=0, method='ffill', inplace=True)\n",
        "sorted_combined_matrix_T.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_hRP-xUBwn8",
        "outputId": "59a74eb1-48f1-4311-e144-0288675ff3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['2019-10-28T02:00:00+08:00', '2018-05-28T12:00:00+08:00',\n",
              "       '2018-02-23T17:00:00+08:00', '2018-03-25T14:00:00+08:00',\n",
              "       '2019-11-14T11:00:00+08:00', '2021-06-01T17:00:00+08:00',\n",
              "       '2018-09-09T12:00:00+08:00', '2018-12-04T01:00:00+08:00',\n",
              "       '2019-05-22T20:00:00+08:00', '2020-05-07T23:00:00+08:00',\n",
              "       ...\n",
              "       '2019-08-13T15:00:00+08:00', '2020-12-07T18:00:00+08:00',\n",
              "       '2021-01-15T20:00:00+08:00', '2021-03-24T13:00:00+08:00',\n",
              "       '2018-08-17T02:00:00+08:00', '2020-02-08T22:00:00+08:00',\n",
              "       '2019-04-18T07:00:00+08:00', '2020-12-28T06:00:00+08:00',\n",
              "       '2020-04-14T11:00:00+08:00', '2021-01-09T12:00:00+08:00'],\n",
              "      dtype='object', length=25941)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the combined_matrix data\n",
        "normalized_data = sorted_combined_matrix_T\n",
        "scaler = StandardScaler()\n",
        "scaled_dataset = scaler.fit_transform(normalized_data)"
      ],
      "metadata": {
        "id": "ULQiKpnSB3hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers = ['adam', 'rmsprop']\n",
        "activation_functions = ['relu', 'sigmoid', 'tanh', 'elu', 'selu', 'softmax', 'swish']\n",
        "mse_values = []\n",
        "window_size = 3"
      ],
      "metadata": {
        "id": "jek9llKqmq3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create supervised data\n",
        "def to_supervised(train):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(window_size, len(train)):\n",
        "        X.append(train[i - window_size:i, :])\n",
        "        Y.append(train[i, 0:1])\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "D34Gg6ub-i-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for optimizer in optimizers:\n",
        "    for activation in activation_functions:\n",
        "        # Load or create your 'scaled_dataset' here\n",
        "\n",
        "        # Create supervised data\n",
        "        X, Y = to_supervised(scaled_dataset)\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        test_size = 0.2\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
        "\n",
        "        # Build the LSTM model\n",
        "        model = Sequential()\n",
        "        model.add(GRU(units=100, return_sequences=True, input_shape=(window_size, X_train.shape[2]), activation=activation))\n",
        "        model.add(GRU(units=100, return_sequences=True, activation=activation))\n",
        "        model.add(GRU(units=100, activation=activation))\n",
        "        model.add(Dense(units=100))\n",
        "        model.add(Dense(units=X_train.shape[2]))\n",
        "        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "        # Train the model\n",
        "        lstm_history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=100, batch_size=256, verbose=2)\n",
        "\n",
        "        # Make predictions and calculate MSE\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_reduced = y_pred.mean(axis=1)\n",
        "        mse = mean_squared_error(Y_test, y_pred_reduced)\n",
        "\n",
        "        print(\"Average MSE for the \" + str(optimizer) + \" optimizer and \" + str(activation) + \" activation function:\", mse)\n",
        "        mse_values.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duW4xMra-lvp",
        "outputId": "bcf56bfb-d883-4f2d-b473-5d44ec48d590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 11s - loss: 0.9762 - val_loss: 1.0964 - 11s/epoch - 134ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9763 - val_loss: 1.0955 - 2s/epoch - 21ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9754 - val_loss: 1.0953 - 2s/epoch - 21ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9743 - val_loss: 1.1007 - 2s/epoch - 21ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9712 - val_loss: 1.0966 - 2s/epoch - 21ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9666 - val_loss: 1.0982 - 2s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9594 - val_loss: 1.1053 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9499 - val_loss: 1.1107 - 2s/epoch - 21ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9446 - val_loss: 1.1168 - 2s/epoch - 22ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9208 - val_loss: 1.1186 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.8981 - val_loss: 1.1563 - 2s/epoch - 20ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.8715 - val_loss: 1.1814 - 2s/epoch - 20ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.8369 - val_loss: 1.2673 - 2s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.8010 - val_loss: 1.2176 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.7535 - val_loss: 1.3108 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.7213 - val_loss: 1.2392 - 2s/epoch - 21ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.6849 - val_loss: 1.2223 - 2s/epoch - 22ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.6498 - val_loss: 1.2435 - 2s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.6259 - val_loss: 1.3786 - 2s/epoch - 20ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.5820 - val_loss: 1.3149 - 2s/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.5543 - val_loss: 1.3273 - 2s/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.5292 - val_loss: 1.4579 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.5106 - val_loss: 1.3218 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.4742 - val_loss: 1.3799 - 2s/epoch - 21ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.4446 - val_loss: 1.4790 - 2s/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.4297 - val_loss: 1.4961 - 2s/epoch - 20ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.3943 - val_loss: 1.3923 - 2s/epoch - 20ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.3689 - val_loss: 1.3820 - 2s/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.3370 - val_loss: 1.4867 - 2s/epoch - 19ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.3278 - val_loss: 1.4230 - 2s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.3053 - val_loss: 1.4427 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.2974 - val_loss: 1.4622 - 2s/epoch - 21ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.2774 - val_loss: 1.4760 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.2554 - val_loss: 1.4881 - 2s/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.2324 - val_loss: 1.5272 - 2s/epoch - 20ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.2232 - val_loss: 1.5366 - 2s/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.2081 - val_loss: 1.5384 - 2s/epoch - 20ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.1905 - val_loss: 1.5984 - 2s/epoch - 20ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.1862 - val_loss: 1.6286 - 2s/epoch - 21ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.1751 - val_loss: 1.6085 - 2s/epoch - 21ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.1560 - val_loss: 1.6342 - 2s/epoch - 21ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.1542 - val_loss: 1.6038 - 2s/epoch - 21ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.1413 - val_loss: 1.6021 - 2s/epoch - 20ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.1411 - val_loss: 1.5685 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.1290 - val_loss: 1.6680 - 2s/epoch - 21ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.1279 - val_loss: 1.6858 - 2s/epoch - 21ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.1278 - val_loss: 1.6040 - 2s/epoch - 20ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.1100 - val_loss: 1.6692 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.0988 - val_loss: 1.6750 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.0916 - val_loss: 1.6674 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.0813 - val_loss: 1.6452 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.0782 - val_loss: 1.6629 - 2s/epoch - 20ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.0745 - val_loss: 1.7122 - 2s/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.0679 - val_loss: 1.7246 - 2s/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.0618 - val_loss: 1.7486 - 2s/epoch - 21ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.0597 - val_loss: 1.7102 - 2s/epoch - 19ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.0557 - val_loss: 1.7093 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.0525 - val_loss: 1.7468 - 2s/epoch - 20ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.0528 - val_loss: 1.7218 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.0553 - val_loss: 1.7337 - 2s/epoch - 20ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.0507 - val_loss: 1.7657 - 2s/epoch - 19ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.0545 - val_loss: 1.7636 - 2s/epoch - 20ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.0549 - val_loss: 1.7230 - 2s/epoch - 21ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.0460 - val_loss: 1.7154 - 2s/epoch - 21ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.0403 - val_loss: 1.7118 - 2s/epoch - 21ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.0349 - val_loss: 1.7403 - 2s/epoch - 21ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.0313 - val_loss: 1.7586 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.0366 - val_loss: 1.6913 - 2s/epoch - 19ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.0439 - val_loss: 1.7390 - 2s/epoch - 20ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.0406 - val_loss: 1.7543 - 2s/epoch - 21ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.0468 - val_loss: 1.6865 - 2s/epoch - 20ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.0500 - val_loss: 1.7664 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.0505 - val_loss: 1.6873 - 2s/epoch - 20ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.0480 - val_loss: 1.7113 - 2s/epoch - 20ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.0406 - val_loss: 1.7159 - 2s/epoch - 20ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.0290 - val_loss: 1.6934 - 2s/epoch - 20ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.0246 - val_loss: 1.6805 - 2s/epoch - 20ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.0213 - val_loss: 1.7183 - 2s/epoch - 21ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.0238 - val_loss: 1.7238 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.0273 - val_loss: 1.7618 - 2s/epoch - 19ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.0253 - val_loss: 1.7381 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.0215 - val_loss: 1.7182 - 2s/epoch - 20ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.0275 - val_loss: 1.6996 - 2s/epoch - 20ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.0234 - val_loss: 1.6960 - 2s/epoch - 20ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.0286 - val_loss: 1.6992 - 2s/epoch - 21ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.0249 - val_loss: 1.7407 - 2s/epoch - 21ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.0252 - val_loss: 1.6823 - 2s/epoch - 20ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.0360 - val_loss: 1.7059 - 2s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.0531 - val_loss: 1.7778 - 2s/epoch - 20ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.0611 - val_loss: 1.7185 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.0456 - val_loss: 1.6989 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.0266 - val_loss: 1.7019 - 2s/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.0255 - val_loss: 1.6905 - 2s/epoch - 20ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.0204 - val_loss: 1.6961 - 2s/epoch - 20ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.0173 - val_loss: 1.6840 - 2s/epoch - 19ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.0133 - val_loss: 1.6832 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.0131 - val_loss: 1.7102 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.0120 - val_loss: 1.6923 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0116 - val_loss: 1.6988 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0128 - val_loss: 1.6966 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the adam optimizer and relu activation function: 1.696575788400437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9872 - val_loss: 1.0983 - 6s/epoch - 78ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9773 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9767 - val_loss: 1.1034 - 2s/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9770 - val_loss: 1.0957 - 2s/epoch - 20ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9767 - val_loss: 1.0983 - 2s/epoch - 21ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9767 - val_loss: 1.0982 - 2s/epoch - 19ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9763 - val_loss: 1.0954 - 2s/epoch - 19ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9764 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9764 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0954 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9758 - val_loss: 1.0984 - 2s/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0954 - 2s/epoch - 20ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9759 - val_loss: 1.0956 - 2s/epoch - 21ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9759 - val_loss: 1.0957 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9755 - val_loss: 1.0953 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0955 - 2s/epoch - 19ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9749 - val_loss: 1.0964 - 2s/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9744 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9747 - val_loss: 1.0955 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9736 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9732 - val_loss: 1.0986 - 2s/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9731 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9720 - val_loss: 1.0991 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9757 - val_loss: 1.0991 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.9727 - val_loss: 1.0983 - 2s/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.9714 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.9705 - val_loss: 1.1015 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.9711 - val_loss: 1.0982 - 2s/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.9698 - val_loss: 1.0956 - 2s/epoch - 20ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.9679 - val_loss: 1.1000 - 2s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.9671 - val_loss: 1.1022 - 2s/epoch - 19ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.9671 - val_loss: 1.1040 - 2s/epoch - 20ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.9647 - val_loss: 1.1017 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.9630 - val_loss: 1.1010 - 2s/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.9608 - val_loss: 1.1057 - 2s/epoch - 20ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.9589 - val_loss: 1.1031 - 2s/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.9567 - val_loss: 1.1129 - 2s/epoch - 20ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.9519 - val_loss: 1.1144 - 2s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.9468 - val_loss: 1.1188 - 2s/epoch - 19ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.9386 - val_loss: 1.1175 - 2s/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.9338 - val_loss: 1.1309 - 2s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.9145 - val_loss: 1.1399 - 2s/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.9056 - val_loss: 1.1260 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.8783 - val_loss: 1.1469 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.8581 - val_loss: 1.1500 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.8344 - val_loss: 1.1577 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.8181 - val_loss: 1.2074 - 2s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.8035 - val_loss: 1.2602 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.7940 - val_loss: 1.2128 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.7731 - val_loss: 1.1639 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.7622 - val_loss: 1.1708 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.7548 - val_loss: 1.2800 - 2s/epoch - 20ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.7580 - val_loss: 1.2040 - 2s/epoch - 20ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.7332 - val_loss: 1.2126 - 2s/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.7295 - val_loss: 1.2781 - 2s/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.7149 - val_loss: 1.2089 - 2s/epoch - 20ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.7054 - val_loss: 1.2786 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.7008 - val_loss: 1.3545 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.6915 - val_loss: 1.2132 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.6741 - val_loss: 1.2226 - 2s/epoch - 20ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.6729 - val_loss: 1.2752 - 2s/epoch - 20ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.6681 - val_loss: 1.2703 - 2s/epoch - 19ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.6578 - val_loss: 1.2670 - 2s/epoch - 19ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.6487 - val_loss: 1.2771 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.6419 - val_loss: 1.3513 - 2s/epoch - 19ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.6390 - val_loss: 1.3573 - 2s/epoch - 19ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.6242 - val_loss: 1.3949 - 2s/epoch - 20ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.6175 - val_loss: 1.3243 - 2s/epoch - 20ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.6110 - val_loss: 1.2737 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.6004 - val_loss: 1.3601 - 2s/epoch - 19ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.6052 - val_loss: 1.2479 - 2s/epoch - 19ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.5992 - val_loss: 1.2935 - 2s/epoch - 19ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.5865 - val_loss: 1.3859 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.5798 - val_loss: 1.2871 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.5685 - val_loss: 1.2919 - 2s/epoch - 20ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.5621 - val_loss: 1.4081 - 2s/epoch - 21ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.5562 - val_loss: 1.2947 - 2s/epoch - 20ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.5623 - val_loss: 1.3487 - 2s/epoch - 19ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.5575 - val_loss: 1.3706 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.5432 - val_loss: 1.4034 - 2s/epoch - 19ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.5349 - val_loss: 1.3509 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.5334 - val_loss: 1.2847 - 2s/epoch - 20ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.5379 - val_loss: 1.4127 - 2s/epoch - 20ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.5290 - val_loss: 1.4146 - 2s/epoch - 20ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.5184 - val_loss: 1.4287 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.5104 - val_loss: 1.4184 - 2s/epoch - 20ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.5101 - val_loss: 1.3616 - 2s/epoch - 19ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.5059 - val_loss: 1.3974 - 2s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.4966 - val_loss: 1.3509 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.5015 - val_loss: 1.4455 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.4925 - val_loss: 1.4284 - 2s/epoch - 20ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.4868 - val_loss: 1.4273 - 2s/epoch - 20ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.4825 - val_loss: 1.3991 - 2s/epoch - 19ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.4811 - val_loss: 1.4559 - 2s/epoch - 19ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.4852 - val_loss: 1.4516 - 2s/epoch - 19ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.4735 - val_loss: 1.4417 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.4728 - val_loss: 1.5052 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.4702 - val_loss: 1.4766 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.4894 - val_loss: 1.4488 - 2s/epoch - 20ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.4636 - val_loss: 1.4836 - 2s/epoch - 20ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the adam optimizer and sigmoid activation function: 1.4836267901570335\n",
            "Epoch 1/100\n",
            "82/82 - 7s - loss: 0.9771 - val_loss: 1.0969 - 7s/epoch - 81ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 0s - loss: 0.9759 - val_loss: 1.0955 - 458ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 0s - loss: 0.9758 - val_loss: 1.0958 - 463ms/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 0s - loss: 0.9744 - val_loss: 1.0954 - 481ms/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 0s - loss: 0.9733 - val_loss: 1.0989 - 488ms/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 0s - loss: 0.9729 - val_loss: 1.0966 - 500ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 0s - loss: 0.9734 - val_loss: 1.0959 - 499ms/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 0s - loss: 0.9685 - val_loss: 1.0977 - 487ms/epoch - 6ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 0s - loss: 0.9658 - val_loss: 1.0971 - 477ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 0s - loss: 0.9609 - val_loss: 1.1005 - 461ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 0s - loss: 0.9553 - val_loss: 1.1068 - 466ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 0s - loss: 0.9441 - val_loss: 1.1183 - 462ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 0s - loss: 0.9336 - val_loss: 1.1347 - 459ms/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 0s - loss: 0.9078 - val_loss: 1.1314 - 452ms/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 0s - loss: 0.8782 - val_loss: 1.1958 - 452ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 0s - loss: 0.8480 - val_loss: 1.1466 - 450ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 0s - loss: 0.8156 - val_loss: 1.2605 - 452ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 0s - loss: 0.7871 - val_loss: 1.2161 - 447ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 0s - loss: 0.7598 - val_loss: 1.1854 - 447ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 0s - loss: 0.7198 - val_loss: 1.2480 - 454ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 0s - loss: 0.6882 - val_loss: 1.2167 - 452ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 0s - loss: 0.6543 - val_loss: 1.2852 - 482ms/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 0s - loss: 0.6303 - val_loss: 1.2961 - 464ms/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 0s - loss: 0.6049 - val_loss: 1.2952 - 459ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 0s - loss: 0.5825 - val_loss: 1.2904 - 460ms/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 0s - loss: 0.5446 - val_loss: 1.2955 - 456ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 0s - loss: 0.5176 - val_loss: 1.3525 - 455ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 0s - loss: 0.5048 - val_loss: 1.3893 - 449ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 0s - loss: 0.4601 - val_loss: 1.3905 - 450ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 0s - loss: 0.4418 - val_loss: 1.5251 - 457ms/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 0s - loss: 0.5454 - val_loss: 1.4152 - 474ms/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 0s - loss: 0.4084 - val_loss: 1.4288 - 472ms/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 0s - loss: 0.3785 - val_loss: 1.4353 - 483ms/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 0s - loss: 0.3552 - val_loss: 1.4242 - 481ms/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 0s - loss: 0.3347 - val_loss: 1.4240 - 492ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 0s - loss: 0.3184 - val_loss: 1.4697 - 468ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 0s - loss: 0.2953 - val_loss: 1.4998 - 463ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 0s - loss: 0.2773 - val_loss: 1.5678 - 465ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 0s - loss: 0.2661 - val_loss: 1.5761 - 462ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 0s - loss: 0.2533 - val_loss: 1.5663 - 470ms/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 0s - loss: 0.2241 - val_loss: 1.5876 - 465ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 0s - loss: 0.2126 - val_loss: 1.5950 - 465ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 0s - loss: 0.1956 - val_loss: 1.5935 - 470ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 0s - loss: 0.1784 - val_loss: 1.6244 - 463ms/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 0s - loss: 0.1650 - val_loss: 1.6596 - 462ms/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 0s - loss: 0.1523 - val_loss: 1.6893 - 464ms/epoch - 6ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 0s - loss: 0.1382 - val_loss: 1.6584 - 467ms/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 0s - loss: 0.1297 - val_loss: 1.6920 - 477ms/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 0s - loss: 0.1203 - val_loss: 1.6543 - 462ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 0s - loss: 0.1119 - val_loss: 1.6652 - 451ms/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 0s - loss: 0.1111 - val_loss: 1.7344 - 454ms/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 0s - loss: 0.0953 - val_loss: 1.7179 - 450ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 0s - loss: 0.0839 - val_loss: 1.7468 - 448ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 0s - loss: 0.0867 - val_loss: 1.7047 - 452ms/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 0s - loss: 0.0702 - val_loss: 1.7131 - 448ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 0s - loss: 0.0661 - val_loss: 1.7635 - 456ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 0s - loss: 0.0574 - val_loss: 1.7609 - 463ms/epoch - 6ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 0s - loss: 0.0505 - val_loss: 1.7673 - 480ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 0s - loss: 0.0469 - val_loss: 1.7673 - 491ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 0s - loss: 0.0417 - val_loss: 1.7884 - 483ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 0s - loss: 0.0383 - val_loss: 1.7453 - 479ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 0s - loss: 0.0355 - val_loss: 1.7616 - 486ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 0s - loss: 0.0329 - val_loss: 1.7922 - 456ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 0s - loss: 0.0281 - val_loss: 1.7933 - 455ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 0s - loss: 0.0254 - val_loss: 1.7877 - 455ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 0s - loss: 0.0249 - val_loss: 1.7964 - 452ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 0s - loss: 0.0239 - val_loss: 1.7992 - 454ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 0s - loss: 0.0223 - val_loss: 1.8003 - 446ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 0s - loss: 0.0244 - val_loss: 1.7904 - 455ms/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 0s - loss: 0.0210 - val_loss: 1.7871 - 451ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 0s - loss: 0.0264 - val_loss: 1.7502 - 458ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 0s - loss: 0.0237 - val_loss: 1.7797 - 457ms/epoch - 6ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 0s - loss: 0.0191 - val_loss: 1.8059 - 459ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 0s - loss: 0.0184 - val_loss: 1.8044 - 461ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 0s - loss: 0.0164 - val_loss: 1.7574 - 463ms/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 0s - loss: 0.0174 - val_loss: 1.7915 - 466ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 0s - loss: 0.0148 - val_loss: 1.7844 - 460ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 0s - loss: 0.0150 - val_loss: 1.7666 - 470ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 0s - loss: 0.0135 - val_loss: 1.7710 - 464ms/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 0s - loss: 0.0153 - val_loss: 1.7737 - 467ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 0s - loss: 0.0209 - val_loss: 1.7811 - 468ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 0s - loss: 0.0217 - val_loss: 1.7496 - 469ms/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 0s - loss: 0.0325 - val_loss: 1.7702 - 463ms/epoch - 6ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 0s - loss: 0.0206 - val_loss: 1.7513 - 487ms/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 0s - loss: 0.0166 - val_loss: 1.7576 - 483ms/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 0s - loss: 0.0128 - val_loss: 1.7437 - 486ms/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 1s - loss: 0.0132 - val_loss: 1.7496 - 508ms/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 1s - loss: 0.0120 - val_loss: 1.7565 - 501ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 0s - loss: 0.0125 - val_loss: 1.7170 - 473ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 0s - loss: 0.0154 - val_loss: 1.7477 - 457ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 0s - loss: 0.0162 - val_loss: 1.7517 - 456ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 0s - loss: 0.0144 - val_loss: 1.7332 - 452ms/epoch - 6ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 0s - loss: 0.0107 - val_loss: 1.7573 - 456ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 0s - loss: 0.0094 - val_loss: 1.7352 - 449ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 0s - loss: 0.0085 - val_loss: 1.7576 - 453ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 0s - loss: 0.0184 - val_loss: 1.7223 - 447ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 0s - loss: 0.0287 - val_loss: 1.7264 - 460ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 0s - loss: 0.0228 - val_loss: 1.7210 - 452ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 0s - loss: 0.0189 - val_loss: 1.7134 - 451ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 0s - loss: 0.0220 - val_loss: 1.7023 - 457ms/epoch - 6ms/step\n",
            "163/163 [==============================] - 1s 2ms/step\n",
            "Average MSE for the adam optimizer and tanh activation function: 1.7022734607464867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9774 - val_loss: 1.0961 - 6s/epoch - 78ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9758 - val_loss: 1.0966 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9752 - val_loss: 1.0991 - 2s/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9734 - val_loss: 1.1017 - 2s/epoch - 19ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9727 - val_loss: 1.0971 - 2s/epoch - 18ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9700 - val_loss: 1.0996 - 2s/epoch - 19ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9663 - val_loss: 1.0979 - 2s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9606 - val_loss: 1.1171 - 2s/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9544 - val_loss: 1.1071 - 2s/epoch - 20ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9461 - val_loss: 1.1183 - 2s/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9295 - val_loss: 1.1134 - 2s/epoch - 20ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9172 - val_loss: 1.1324 - 2s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.8957 - val_loss: 1.1377 - 2s/epoch - 19ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.8819 - val_loss: 1.1476 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.8510 - val_loss: 1.1452 - 2s/epoch - 21ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.8216 - val_loss: 1.2223 - 2s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.8012 - val_loss: 1.1774 - 2s/epoch - 19ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.7620 - val_loss: 1.2090 - 2s/epoch - 20ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.7320 - val_loss: 1.2429 - 2s/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.6983 - val_loss: 1.3109 - 2s/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.6694 - val_loss: 1.2625 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.6337 - val_loss: 1.2698 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.6091 - val_loss: 1.2820 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.5729 - val_loss: 1.3098 - 2s/epoch - 19ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.5311 - val_loss: 1.4025 - 2s/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.5171 - val_loss: 1.4491 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.4738 - val_loss: 1.3915 - 2s/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.4301 - val_loss: 1.4451 - 2s/epoch - 19ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.3949 - val_loss: 1.4515 - 2s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.3706 - val_loss: 1.5455 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.3486 - val_loss: 1.4758 - 2s/epoch - 21ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.3288 - val_loss: 1.5220 - 2s/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.3013 - val_loss: 1.5613 - 2s/epoch - 19ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.2676 - val_loss: 1.6210 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.2542 - val_loss: 1.6361 - 2s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.2226 - val_loss: 1.5557 - 2s/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.1956 - val_loss: 1.6340 - 2s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.2149 - val_loss: 1.6756 - 2s/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.1735 - val_loss: 1.6722 - 2s/epoch - 20ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.1488 - val_loss: 1.7129 - 2s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.1376 - val_loss: 1.6683 - 2s/epoch - 20ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.1208 - val_loss: 1.7251 - 2s/epoch - 20ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.1101 - val_loss: 1.7580 - 2s/epoch - 19ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.0964 - val_loss: 1.7637 - 2s/epoch - 19ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.0877 - val_loss: 1.7546 - 2s/epoch - 19ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.0834 - val_loss: 1.7365 - 2s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.0737 - val_loss: 1.7272 - 2s/epoch - 20ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.0654 - val_loss: 1.8170 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.0636 - val_loss: 1.7803 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.0511 - val_loss: 1.7974 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.0472 - val_loss: 1.8001 - 2s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.0402 - val_loss: 1.8044 - 2s/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.0370 - val_loss: 1.8329 - 2s/epoch - 19ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.0339 - val_loss: 1.8307 - 2s/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.0321 - val_loss: 1.8190 - 2s/epoch - 20ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.0274 - val_loss: 1.8299 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.0285 - val_loss: 1.8319 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.0252 - val_loss: 1.8373 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.0240 - val_loss: 1.8201 - 2s/epoch - 19ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.0204 - val_loss: 1.8336 - 2s/epoch - 19ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.0199 - val_loss: 1.8391 - 2s/epoch - 19ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.0178 - val_loss: 1.8281 - 2s/epoch - 20ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.0193 - val_loss: 1.7943 - 2s/epoch - 20ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.0185 - val_loss: 1.7937 - 2s/epoch - 20ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.0185 - val_loss: 1.8074 - 2s/epoch - 19ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.0183 - val_loss: 1.8211 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.0189 - val_loss: 1.8161 - 2s/epoch - 19ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.0171 - val_loss: 1.8160 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.0230 - val_loss: 1.8533 - 2s/epoch - 19ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.0412 - val_loss: 1.8253 - 2s/epoch - 19ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.0303 - val_loss: 1.7669 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.0198 - val_loss: 1.7669 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.0139 - val_loss: 1.7707 - 2s/epoch - 20ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.0127 - val_loss: 1.7718 - 2s/epoch - 20ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.0104 - val_loss: 1.7786 - 2s/epoch - 20ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.0108 - val_loss: 1.7910 - 2s/epoch - 19ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.0123 - val_loss: 1.7983 - 2s/epoch - 19ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.0169 - val_loss: 1.7699 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.0152 - val_loss: 1.7804 - 2s/epoch - 20ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.0139 - val_loss: 1.7594 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.0121 - val_loss: 1.7635 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.0153 - val_loss: 1.7495 - 2s/epoch - 19ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.0139 - val_loss: 1.7711 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.0161 - val_loss: 1.7510 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.0175 - val_loss: 1.7448 - 2s/epoch - 19ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.0147 - val_loss: 1.7441 - 2s/epoch - 20ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.0197 - val_loss: 1.7358 - 2s/epoch - 20ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.0154 - val_loss: 1.7692 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.0156 - val_loss: 1.7196 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.0147 - val_loss: 1.7591 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.0168 - val_loss: 1.7507 - 2s/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.0147 - val_loss: 1.7389 - 2s/epoch - 19ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.0136 - val_loss: 1.7007 - 2s/epoch - 19ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.0119 - val_loss: 1.7222 - 2s/epoch - 20ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.0123 - val_loss: 1.7459 - 2s/epoch - 21ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.0125 - val_loss: 1.7016 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.0158 - val_loss: 1.6714 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0153 - val_loss: 1.6918 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0125 - val_loss: 1.7090 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the adam optimizer and elu activation function: 1.708962638406095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9800 - val_loss: 1.0971 - 6s/epoch - 77ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9763 - val_loss: 1.0973 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9756 - val_loss: 1.0988 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9745 - val_loss: 1.1028 - 2s/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9732 - val_loss: 1.0996 - 2s/epoch - 19ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9725 - val_loss: 1.1010 - 2s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9696 - val_loss: 1.1096 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9712 - val_loss: 1.1092 - 2s/epoch - 19ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9642 - val_loss: 1.1114 - 2s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9569 - val_loss: 1.1075 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9484 - val_loss: 1.1089 - 2s/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9349 - val_loss: 1.1150 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9168 - val_loss: 1.1432 - 2s/epoch - 19ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.8880 - val_loss: 1.1405 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.8534 - val_loss: 1.1199 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.8137 - val_loss: 1.1868 - 2s/epoch - 19ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.7741 - val_loss: 1.1759 - 2s/epoch - 18ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.7189 - val_loss: 1.2722 - 2s/epoch - 19ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.6992 - val_loss: 1.2291 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.6381 - val_loss: 1.2480 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.5879 - val_loss: 1.3064 - 2s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.5586 - val_loss: 1.2899 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.5068 - val_loss: 1.4026 - 2s/epoch - 21ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.4812 - val_loss: 1.3790 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.4318 - val_loss: 1.4152 - 2s/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.4065 - val_loss: 1.4048 - 2s/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.3680 - val_loss: 1.4164 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.3323 - val_loss: 1.4349 - 2s/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.3025 - val_loss: 1.5048 - 2s/epoch - 19ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.2709 - val_loss: 1.5049 - 2s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.2413 - val_loss: 1.5457 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.2162 - val_loss: 1.5880 - 2s/epoch - 19ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.1956 - val_loss: 1.5712 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.1756 - val_loss: 1.6090 - 2s/epoch - 19ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.1480 - val_loss: 1.6077 - 2s/epoch - 20ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.1382 - val_loss: 1.6570 - 2s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.1168 - val_loss: 1.6753 - 2s/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.1003 - val_loss: 1.6425 - 2s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.0901 - val_loss: 1.6312 - 2s/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.0898 - val_loss: 1.6511 - 2s/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.0776 - val_loss: 1.6311 - 2s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.0664 - val_loss: 1.6729 - 2s/epoch - 20ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.0601 - val_loss: 1.6617 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.0480 - val_loss: 1.7084 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.0417 - val_loss: 1.7141 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.0377 - val_loss: 1.6647 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.0317 - val_loss: 1.6780 - 2s/epoch - 20ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.0350 - val_loss: 1.7258 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.0286 - val_loss: 1.6975 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.0251 - val_loss: 1.6987 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.0269 - val_loss: 1.7217 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.0239 - val_loss: 1.6953 - 2s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.0222 - val_loss: 1.7098 - 2s/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.0280 - val_loss: 1.7013 - 2s/epoch - 19ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.0277 - val_loss: 1.7059 - 2s/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.0338 - val_loss: 1.7034 - 2s/epoch - 19ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.0291 - val_loss: 1.6754 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.0207 - val_loss: 1.6907 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.0187 - val_loss: 1.6905 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.0172 - val_loss: 1.6988 - 2s/epoch - 19ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.0142 - val_loss: 1.6924 - 2s/epoch - 19ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.0138 - val_loss: 1.6763 - 2s/epoch - 19ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.0217 - val_loss: 1.6558 - 2s/epoch - 20ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.0356 - val_loss: 1.6794 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.0410 - val_loss: 1.6508 - 2s/epoch - 20ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.0336 - val_loss: 1.6428 - 2s/epoch - 20ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.0296 - val_loss: 1.6071 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.0232 - val_loss: 1.6261 - 2s/epoch - 19ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.0152 - val_loss: 1.6474 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.0110 - val_loss: 1.6477 - 2s/epoch - 20ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.0094 - val_loss: 1.6570 - 2s/epoch - 20ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.0084 - val_loss: 1.6483 - 2s/epoch - 19ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.0094 - val_loss: 1.6459 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.0116 - val_loss: 1.6302 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.0157 - val_loss: 1.6818 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.0210 - val_loss: 1.6096 - 2s/epoch - 19ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.0181 - val_loss: 1.6205 - 2s/epoch - 19ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.0159 - val_loss: 1.6141 - 2s/epoch - 20ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.0145 - val_loss: 1.6440 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.0299 - val_loss: 1.6681 - 2s/epoch - 19ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.0208 - val_loss: 1.6329 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.0179 - val_loss: 1.6073 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.0176 - val_loss: 1.6028 - 2s/epoch - 19ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.0130 - val_loss: 1.6032 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.0120 - val_loss: 1.6011 - 2s/epoch - 19ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.0101 - val_loss: 1.6273 - 2s/epoch - 20ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.0097 - val_loss: 1.6229 - 2s/epoch - 20ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.0088 - val_loss: 1.6033 - 2s/epoch - 20ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.0086 - val_loss: 1.6139 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.0104 - val_loss: 1.6247 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.0151 - val_loss: 1.6247 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.0152 - val_loss: 1.6283 - 2s/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.0185 - val_loss: 1.5840 - 2s/epoch - 19ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.0186 - val_loss: 1.5787 - 2s/epoch - 20ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.0227 - val_loss: 1.6011 - 2s/epoch - 20ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.0235 - val_loss: 1.6028 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.0192 - val_loss: 1.6134 - 2s/epoch - 20ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.0179 - val_loss: 1.5698 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0145 - val_loss: 1.5864 - 2s/epoch - 20ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0114 - val_loss: 1.5920 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the adam optimizer and selu activation function: 1.5919721724509737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9761 - val_loss: 1.0961 - 6s/epoch - 77ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 21ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 21ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 21ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0957 - 2s/epoch - 20ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0956 - 2s/epoch - 20ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0957 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0957 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 21ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 21ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the adam optimizer and softmax activation function: 1.0961801494468337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 7s - loss: 0.9763 - val_loss: 1.0959 - 7s/epoch - 87ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9759 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9755 - val_loss: 1.0964 - 2s/epoch - 20ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9749 - val_loss: 1.0958 - 2s/epoch - 21ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9729 - val_loss: 1.0972 - 2s/epoch - 20ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9718 - val_loss: 1.0977 - 2s/epoch - 21ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9707 - val_loss: 1.0984 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9695 - val_loss: 1.0977 - 2s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9661 - val_loss: 1.1019 - 2s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9622 - val_loss: 1.1059 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9564 - val_loss: 1.1079 - 2s/epoch - 20ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9479 - val_loss: 1.1038 - 2s/epoch - 21ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9357 - val_loss: 1.1217 - 2s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9167 - val_loss: 1.1386 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9001 - val_loss: 1.1693 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.8734 - val_loss: 1.1384 - 2s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.8461 - val_loss: 1.1778 - 2s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.8226 - val_loss: 1.2284 - 2s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.8078 - val_loss: 1.2156 - 2s/epoch - 21ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.7826 - val_loss: 1.2213 - 2s/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.7510 - val_loss: 1.2244 - 2s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.7310 - val_loss: 1.2113 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.7069 - val_loss: 1.2638 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.6871 - val_loss: 1.2599 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.6634 - val_loss: 1.2572 - 2s/epoch - 21ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.6378 - val_loss: 1.2782 - 2s/epoch - 20ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.6106 - val_loss: 1.3136 - 2s/epoch - 21ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.5862 - val_loss: 1.3583 - 2s/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.5600 - val_loss: 1.3125 - 2s/epoch - 20ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.5268 - val_loss: 1.2989 - 2s/epoch - 20ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.4983 - val_loss: 1.3556 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.4667 - val_loss: 1.4322 - 2s/epoch - 20ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.4471 - val_loss: 1.4204 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.4133 - val_loss: 1.4465 - 2s/epoch - 21ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.3935 - val_loss: 1.4966 - 2s/epoch - 21ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.3607 - val_loss: 1.4985 - 2s/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.3340 - val_loss: 1.5501 - 2s/epoch - 20ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.3155 - val_loss: 1.5639 - 2s/epoch - 20ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.3056 - val_loss: 1.6087 - 2s/epoch - 19ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.2712 - val_loss: 1.5463 - 2s/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.2486 - val_loss: 1.5633 - 2s/epoch - 20ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.2286 - val_loss: 1.5545 - 2s/epoch - 21ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.2132 - val_loss: 1.6121 - 2s/epoch - 20ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.1998 - val_loss: 1.6411 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.1796 - val_loss: 1.6338 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.1642 - val_loss: 1.5973 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.1481 - val_loss: 1.6895 - 2s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.1384 - val_loss: 1.7106 - 2s/epoch - 20ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.1290 - val_loss: 1.6953 - 2s/epoch - 20ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.1163 - val_loss: 1.6665 - 2s/epoch - 20ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.1047 - val_loss: 1.7076 - 2s/epoch - 20ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.0932 - val_loss: 1.7722 - 2s/epoch - 20ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.0880 - val_loss: 1.7660 - 2s/epoch - 20ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.0799 - val_loss: 1.7530 - 2s/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.0736 - val_loss: 1.7459 - 2s/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.0655 - val_loss: 1.7918 - 2s/epoch - 20ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.0637 - val_loss: 1.7502 - 2s/epoch - 20ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.0741 - val_loss: 1.8073 - 2s/epoch - 20ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.0581 - val_loss: 1.7693 - 2s/epoch - 20ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.0486 - val_loss: 1.7639 - 2s/epoch - 20ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.0429 - val_loss: 1.7874 - 2s/epoch - 19ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.0390 - val_loss: 1.7816 - 2s/epoch - 20ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.0377 - val_loss: 1.7961 - 2s/epoch - 20ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.0350 - val_loss: 1.8127 - 2s/epoch - 20ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.0317 - val_loss: 1.8126 - 2s/epoch - 21ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.0304 - val_loss: 1.7714 - 2s/epoch - 20ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.0287 - val_loss: 1.7961 - 2s/epoch - 20ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.0313 - val_loss: 1.7962 - 2s/epoch - 20ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.0340 - val_loss: 1.8058 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.0325 - val_loss: 1.7878 - 2s/epoch - 20ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.0372 - val_loss: 1.8189 - 2s/epoch - 19ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.0248 - val_loss: 1.7829 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.0195 - val_loss: 1.8000 - 2s/epoch - 20ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.0181 - val_loss: 1.7723 - 2s/epoch - 20ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.0164 - val_loss: 1.7908 - 2s/epoch - 20ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.0144 - val_loss: 1.7918 - 2s/epoch - 20ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.0148 - val_loss: 1.8153 - 2s/epoch - 20ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.0147 - val_loss: 1.7834 - 2s/epoch - 19ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.0149 - val_loss: 1.7785 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.0142 - val_loss: 1.7904 - 2s/epoch - 21ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.0182 - val_loss: 1.7572 - 2s/epoch - 20ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.0212 - val_loss: 1.7770 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.0226 - val_loss: 1.7427 - 2s/epoch - 20ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.0204 - val_loss: 1.7787 - 2s/epoch - 20ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.0187 - val_loss: 1.7760 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.0173 - val_loss: 1.7623 - 2s/epoch - 21ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.0199 - val_loss: 1.7657 - 2s/epoch - 21ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.0158 - val_loss: 1.7795 - 2s/epoch - 21ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.0147 - val_loss: 1.7200 - 2s/epoch - 21ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.0141 - val_loss: 1.7728 - 2s/epoch - 20ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.0121 - val_loss: 1.7502 - 2s/epoch - 21ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.0124 - val_loss: 1.7564 - 2s/epoch - 20ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.0100 - val_loss: 1.7614 - 2s/epoch - 21ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.0321 - val_loss: 1.7557 - 2s/epoch - 21ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.0328 - val_loss: 1.6648 - 2s/epoch - 21ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.0292 - val_loss: 1.7169 - 2s/epoch - 22ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.0187 - val_loss: 1.6768 - 2s/epoch - 20ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.0119 - val_loss: 1.7115 - 2s/epoch - 20ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0115 - val_loss: 1.7109 - 2s/epoch - 21ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0078 - val_loss: 1.7264 - 2s/epoch - 20ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the adam optimizer and swish activation function: 1.726414302468425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9763 - val_loss: 1.0961 - 6s/epoch - 74ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9759 - val_loss: 1.0950 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9756 - val_loss: 1.0952 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9752 - val_loss: 1.0950 - 2s/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9747 - val_loss: 1.0956 - 2s/epoch - 18ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9736 - val_loss: 1.0959 - 2s/epoch - 18ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9722 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9700 - val_loss: 1.1033 - 2s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9671 - val_loss: 1.1197 - 2s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9652 - val_loss: 1.1456 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9630 - val_loss: 1.1037 - 2s/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9565 - val_loss: 1.1348 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9531 - val_loss: 1.1281 - 2s/epoch - 19ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9474 - val_loss: 1.1417 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9392 - val_loss: 1.1917 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9329 - val_loss: 1.2408 - 2s/epoch - 19ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9223 - val_loss: 1.1360 - 2s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9120 - val_loss: 1.2067 - 2s/epoch - 19ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9004 - val_loss: 1.1887 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.8816 - val_loss: 1.2307 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.8750 - val_loss: 1.3093 - 2s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.8560 - val_loss: 1.1895 - 2s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.8442 - val_loss: 1.2203 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.8211 - val_loss: 1.2847 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.7965 - val_loss: 1.2128 - 2s/epoch - 19ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.7863 - val_loss: 1.1774 - 2s/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.7584 - val_loss: 1.2764 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.7473 - val_loss: 1.2380 - 2s/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.7231 - val_loss: 1.2006 - 2s/epoch - 18ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.7170 - val_loss: 1.2141 - 2s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.6915 - val_loss: 1.5884 - 2s/epoch - 19ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.6635 - val_loss: 1.2095 - 2s/epoch - 20ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.6515 - val_loss: 1.2247 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.6217 - val_loss: 1.9334 - 2s/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.6371 - val_loss: 1.2347 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.6022 - val_loss: 1.2262 - 2s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.5910 - val_loss: 1.2890 - 2s/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.5745 - val_loss: 3.4879 - 2s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.5690 - val_loss: 1.2289 - 2s/epoch - 21ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.5461 - val_loss: 1.2462 - 2s/epoch - 20ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.5255 - val_loss: 1.4912 - 2s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.5175 - val_loss: 1.2727 - 2s/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.5031 - val_loss: 1.2933 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.4951 - val_loss: 1.9020 - 2s/epoch - 19ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.4841 - val_loss: 1.4783 - 2s/epoch - 19ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.4754 - val_loss: 1.3355 - 2s/epoch - 19ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.4577 - val_loss: 1.3385 - 2s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.4541 - val_loss: 1.4044 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.4259 - val_loss: 1.2536 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.4193 - val_loss: 1.3449 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.4110 - val_loss: 1.4469 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.3964 - val_loss: 1.9223 - 2s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.3904 - val_loss: 1.3045 - 2s/epoch - 20ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.3735 - val_loss: 1.2492 - 2s/epoch - 19ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.3671 - val_loss: 1.6823 - 2s/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.3512 - val_loss: 1.5153 - 2s/epoch - 20ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.3456 - val_loss: 1.5583 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.3377 - val_loss: 1.4636 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.3278 - val_loss: 1.4823 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.3165 - val_loss: 1.4389 - 2s/epoch - 18ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.3084 - val_loss: 1.4181 - 2s/epoch - 19ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.2988 - val_loss: 1.3707 - 2s/epoch - 18ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.2865 - val_loss: 1.3875 - 2s/epoch - 20ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.2789 - val_loss: 1.6636 - 2s/epoch - 20ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.2749 - val_loss: 1.4354 - 2s/epoch - 19ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.2645 - val_loss: 1.6149 - 2s/epoch - 19ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.2579 - val_loss: 1.5830 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.2507 - val_loss: 1.3628 - 2s/epoch - 19ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.2415 - val_loss: 1.4983 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.2320 - val_loss: 1.3840 - 2s/epoch - 19ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.2226 - val_loss: 1.5387 - 2s/epoch - 20ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.2213 - val_loss: 1.6590 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.2107 - val_loss: 1.5319 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.2085 - val_loss: 1.4795 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.2006 - val_loss: 1.4996 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.1902 - val_loss: 1.6623 - 2s/epoch - 19ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.1853 - val_loss: 1.6141 - 2s/epoch - 19ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.1788 - val_loss: 1.4750 - 2s/epoch - 18ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.1762 - val_loss: 1.6405 - 2s/epoch - 20ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.1677 - val_loss: 1.7953 - 2s/epoch - 20ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.1647 - val_loss: 1.6832 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.1605 - val_loss: 1.4356 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.1544 - val_loss: 1.5520 - 2s/epoch - 20ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.1473 - val_loss: 1.4440 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.1411 - val_loss: 1.5126 - 2s/epoch - 19ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.1422 - val_loss: 1.5375 - 2s/epoch - 19ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.1378 - val_loss: 1.5671 - 2s/epoch - 21ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.1282 - val_loss: 1.5939 - 2s/epoch - 20ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.1354 - val_loss: 1.5246 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.1251 - val_loss: 1.6435 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.1211 - val_loss: 1.5099 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.1193 - val_loss: 1.5851 - 2s/epoch - 18ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.1153 - val_loss: 1.5421 - 2s/epoch - 18ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 1s - loss: 0.1106 - val_loss: 1.5726 - 1s/epoch - 18ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.1074 - val_loss: 1.5115 - 2s/epoch - 19ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.1066 - val_loss: 1.6758 - 2s/epoch - 20ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.1035 - val_loss: 1.6860 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.1012 - val_loss: 1.6829 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0981 - val_loss: 1.5794 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0924 - val_loss: 1.5747 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the rmsprop optimizer and relu activation function: 1.5745033534170478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9852 - val_loss: 1.1105 - 6s/epoch - 71ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9804 - val_loss: 1.1180 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9791 - val_loss: 1.1028 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9781 - val_loss: 1.0982 - 2s/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9774 - val_loss: 1.1041 - 2s/epoch - 19ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9771 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9769 - val_loss: 1.0973 - 2s/epoch - 19ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9766 - val_loss: 1.0967 - 2s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9766 - val_loss: 1.0983 - 2s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 1s - loss: 0.9764 - val_loss: 1.1004 - 1s/epoch - 18ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9765 - val_loss: 1.1030 - 2s/epoch - 18ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9764 - val_loss: 1.0974 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9763 - val_loss: 1.0967 - 2s/epoch - 19ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0981 - 2s/epoch - 19ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0981 - 2s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 1s - loss: 0.9762 - val_loss: 1.0976 - 1s/epoch - 18ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0979 - 2s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0974 - 2s/epoch - 19ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0969 - 2s/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0965 - 2s/epoch - 20ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0989 - 2s/epoch - 19ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 18ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0968 - 2s/epoch - 19ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 18ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 1s - loss: 0.9761 - val_loss: 1.0959 - 1s/epoch - 18ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 18ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 1s - loss: 0.9760 - val_loss: 1.0962 - 1s/epoch - 18ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0966 - 2s/epoch - 20ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 1s - loss: 0.9761 - val_loss: 1.0962 - 1s/epoch - 18ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 18ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 1s - loss: 0.9760 - val_loss: 1.0963 - 1s/epoch - 18ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0970 - 2s/epoch - 20ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 18ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 1s - loss: 0.9761 - val_loss: 1.0961 - 1s/epoch - 18ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 18ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0968 - 2s/epoch - 19ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0972 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 18ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0976 - 2s/epoch - 20ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0975 - 2s/epoch - 19ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0966 - 2s/epoch - 19ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0965 - 2s/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 1s - loss: 0.9760 - val_loss: 1.0969 - 1s/epoch - 18ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 1s - loss: 0.9761 - val_loss: 1.0970 - 1s/epoch - 18ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0967 - 2s/epoch - 18ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0965 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0965 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the rmsprop optimizer and sigmoid activation function: 1.0960931381453745\n",
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9776 - val_loss: 1.0962 - 6s/epoch - 73ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 0s - loss: 0.9764 - val_loss: 1.0959 - 469ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 0s - loss: 0.9759 - val_loss: 1.0964 - 467ms/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 0s - loss: 0.9754 - val_loss: 1.0983 - 450ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 0s - loss: 0.9749 - val_loss: 1.0978 - 449ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 0s - loss: 0.9742 - val_loss: 1.0961 - 446ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 0s - loss: 0.9739 - val_loss: 1.1002 - 445ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 0s - loss: 0.9736 - val_loss: 1.0981 - 449ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 0s - loss: 0.9733 - val_loss: 1.0971 - 446ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 0s - loss: 0.9723 - val_loss: 1.1011 - 446ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 0s - loss: 0.9720 - val_loss: 1.0964 - 444ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 0s - loss: 0.9712 - val_loss: 1.1002 - 445ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 0s - loss: 0.9702 - val_loss: 1.1065 - 444ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 0s - loss: 0.9697 - val_loss: 1.0963 - 444ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 0s - loss: 0.9689 - val_loss: 1.1002 - 453ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 0s - loss: 0.9675 - val_loss: 1.1068 - 451ms/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 0s - loss: 0.9662 - val_loss: 1.1358 - 453ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 0s - loss: 0.9648 - val_loss: 1.1028 - 448ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 0s - loss: 0.9628 - val_loss: 1.1025 - 448ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 0s - loss: 0.9617 - val_loss: 1.1206 - 459ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 0s - loss: 0.9601 - val_loss: 1.1111 - 453ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 0s - loss: 0.9572 - val_loss: 1.1026 - 455ms/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 0s - loss: 0.9557 - val_loss: 1.1217 - 450ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 0s - loss: 0.9520 - val_loss: 1.1306 - 458ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 0s - loss: 0.9474 - val_loss: 1.1374 - 467ms/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 0s - loss: 0.9452 - val_loss: 1.1579 - 473ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 0s - loss: 0.9422 - val_loss: 1.1184 - 489ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 0s - loss: 0.9365 - val_loss: 1.1230 - 485ms/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 0s - loss: 0.9310 - val_loss: 1.1333 - 471ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 0s - loss: 0.9241 - val_loss: 1.2317 - 464ms/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 0s - loss: 0.9167 - val_loss: 1.1266 - 443ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 0s - loss: 0.9112 - val_loss: 1.1278 - 446ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 0s - loss: 0.9014 - val_loss: 1.1722 - 443ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 0s - loss: 0.8905 - val_loss: 1.1755 - 445ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 0s - loss: 0.8778 - val_loss: 1.1925 - 444ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 0s - loss: 0.8647 - val_loss: 1.1565 - 446ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 0s - loss: 0.8555 - val_loss: 1.1544 - 443ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 0s - loss: 0.8414 - val_loss: 1.2735 - 445ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 0s - loss: 0.8231 - val_loss: 1.1611 - 447ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 0s - loss: 0.8084 - val_loss: 1.2121 - 445ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 0s - loss: 0.7976 - val_loss: 1.2246 - 443ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 0s - loss: 0.7783 - val_loss: 1.3092 - 443ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 0s - loss: 0.7623 - val_loss: 1.8657 - 441ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 0s - loss: 0.7520 - val_loss: 1.3502 - 443ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 0s - loss: 0.7352 - val_loss: 1.3743 - 440ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 0s - loss: 0.7185 - val_loss: 1.3733 - 445ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 0s - loss: 0.7064 - val_loss: 1.2231 - 441ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 0s - loss: 0.6928 - val_loss: 1.2485 - 445ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 0s - loss: 0.6821 - val_loss: 1.5421 - 446ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 0s - loss: 0.6653 - val_loss: 1.2626 - 442ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 0s - loss: 0.6540 - val_loss: 1.3399 - 448ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 0s - loss: 0.6422 - val_loss: 1.9067 - 450ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 0s - loss: 0.6334 - val_loss: 1.3085 - 475ms/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 0s - loss: 0.6176 - val_loss: 1.2968 - 477ms/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 0s - loss: 0.6054 - val_loss: 1.3462 - 478ms/epoch - 6ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 0s - loss: 0.5941 - val_loss: 1.3330 - 481ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 0s - loss: 0.5841 - val_loss: 1.2409 - 498ms/epoch - 6ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 0s - loss: 0.5692 - val_loss: 1.9737 - 456ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 0s - loss: 0.5604 - val_loss: 1.3917 - 454ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 0s - loss: 0.5456 - val_loss: 1.4484 - 460ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 0s - loss: 0.5343 - val_loss: 1.4215 - 465ms/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 0s - loss: 0.5219 - val_loss: 1.9472 - 456ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 0s - loss: 0.5127 - val_loss: 1.6031 - 459ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 0s - loss: 0.5023 - val_loss: 1.7963 - 458ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 0s - loss: 0.4879 - val_loss: 1.4444 - 453ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 0s - loss: 0.4736 - val_loss: 1.3138 - 445ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 0s - loss: 0.4674 - val_loss: 1.4656 - 461ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 0s - loss: 0.4516 - val_loss: 1.5009 - 463ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 0s - loss: 0.4442 - val_loss: 1.4867 - 451ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 0s - loss: 0.4348 - val_loss: 1.4845 - 444ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 0s - loss: 0.4241 - val_loss: 1.7075 - 443ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 0s - loss: 0.4105 - val_loss: 1.8273 - 445ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 0s - loss: 0.4040 - val_loss: 1.5834 - 445ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 0s - loss: 0.3910 - val_loss: 2.1367 - 442ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 0s - loss: 0.3827 - val_loss: 1.6993 - 439ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 0s - loss: 0.3703 - val_loss: 1.8397 - 443ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 0s - loss: 0.3608 - val_loss: 1.4208 - 454ms/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 0s - loss: 0.3500 - val_loss: 1.5765 - 447ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 0s - loss: 0.3434 - val_loss: 1.5351 - 448ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 0s - loss: 0.3314 - val_loss: 1.5995 - 467ms/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 0s - loss: 0.3222 - val_loss: 1.7019 - 467ms/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 0s - loss: 0.3093 - val_loss: 1.6133 - 469ms/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 0s - loss: 0.3016 - val_loss: 1.5971 - 472ms/epoch - 6ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 0s - loss: 0.2922 - val_loss: 1.6401 - 473ms/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 0s - loss: 0.2814 - val_loss: 1.7641 - 442ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 0s - loss: 0.2745 - val_loss: 1.6990 - 441ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 0s - loss: 0.2614 - val_loss: 1.7600 - 450ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 0s - loss: 0.2550 - val_loss: 1.8067 - 449ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 0s - loss: 0.2456 - val_loss: 1.6716 - 456ms/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 0s - loss: 0.2351 - val_loss: 1.6348 - 462ms/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 0s - loss: 0.2271 - val_loss: 1.7718 - 449ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 0s - loss: 0.2192 - val_loss: 1.7244 - 455ms/epoch - 6ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 0s - loss: 0.2131 - val_loss: 1.8349 - 461ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 0s - loss: 0.2004 - val_loss: 1.6882 - 454ms/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 0s - loss: 0.1936 - val_loss: 1.7190 - 452ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 0s - loss: 0.1858 - val_loss: 1.7234 - 457ms/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 0s - loss: 0.1757 - val_loss: 1.9568 - 459ms/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 0s - loss: 0.1673 - val_loss: 1.7030 - 454ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 0s - loss: 0.1592 - val_loss: 1.9494 - 456ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 0s - loss: 0.1539 - val_loss: 2.0223 - 457ms/epoch - 6ms/step\n",
            "163/163 [==============================] - 1s 2ms/step\n",
            "Average MSE for the rmsprop optimizer and tanh activation function: 2.022044649278073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9773 - val_loss: 1.0964 - 6s/epoch - 71ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9762 - val_loss: 1.0967 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9756 - val_loss: 1.0977 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9753 - val_loss: 1.0975 - 2s/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9747 - val_loss: 1.0966 - 2s/epoch - 19ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9745 - val_loss: 1.0984 - 2s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9734 - val_loss: 1.0979 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9729 - val_loss: 1.1049 - 2s/epoch - 19ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9731 - val_loss: 1.0985 - 2s/epoch - 19ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9719 - val_loss: 1.1007 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9713 - val_loss: 1.1010 - 2s/epoch - 19ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9711 - val_loss: 1.1004 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9696 - val_loss: 1.1016 - 2s/epoch - 19ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9693 - val_loss: 1.1000 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9685 - val_loss: 1.1002 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9675 - val_loss: 1.1017 - 2s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9662 - val_loss: 1.0992 - 2s/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9641 - val_loss: 1.1061 - 2s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9642 - val_loss: 1.1135 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9619 - val_loss: 1.1096 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9594 - val_loss: 1.1072 - 2s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9585 - val_loss: 1.1102 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9565 - val_loss: 1.1224 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9530 - val_loss: 1.1140 - 2s/epoch - 19ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.9500 - val_loss: 1.1282 - 2s/epoch - 19ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.9449 - val_loss: 1.1121 - 2s/epoch - 20ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.9405 - val_loss: 1.1282 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.9348 - val_loss: 1.1533 - 2s/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.9305 - val_loss: 1.1344 - 2s/epoch - 19ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.9229 - val_loss: 1.1515 - 2s/epoch - 20ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.9161 - val_loss: 1.1628 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.9110 - val_loss: 1.1612 - 2s/epoch - 19ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.9020 - val_loss: 1.1758 - 2s/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.8927 - val_loss: 1.1725 - 2s/epoch - 19ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.8802 - val_loss: 1.2438 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.8661 - val_loss: 1.1944 - 2s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.8547 - val_loss: 1.2792 - 2s/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.8494 - val_loss: 1.2163 - 2s/epoch - 20ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.8289 - val_loss: 1.3647 - 2s/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.8167 - val_loss: 1.1688 - 2s/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.8021 - val_loss: 1.3530 - 2s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.7904 - val_loss: 1.3018 - 2s/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.7787 - val_loss: 1.5289 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.7675 - val_loss: 1.3850 - 2s/epoch - 19ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.7513 - val_loss: 1.2787 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.7369 - val_loss: 1.3682 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.7242 - val_loss: 2.0723 - 2s/epoch - 21ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.7120 - val_loss: 1.2828 - 2s/epoch - 20ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.6952 - val_loss: 1.1649 - 2s/epoch - 20ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.6850 - val_loss: 1.3555 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.6703 - val_loss: 1.3942 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.6538 - val_loss: 1.2487 - 2s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.6427 - val_loss: 1.3484 - 2s/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.6288 - val_loss: 1.4352 - 2s/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.6185 - val_loss: 1.6024 - 2s/epoch - 20ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.6001 - val_loss: 1.4468 - 2s/epoch - 20ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.5836 - val_loss: 1.4694 - 2s/epoch - 20ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.5753 - val_loss: 1.3351 - 2s/epoch - 20ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.5569 - val_loss: 1.3826 - 2s/epoch - 20ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.5467 - val_loss: 1.3958 - 2s/epoch - 19ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.5295 - val_loss: 1.4432 - 2s/epoch - 19ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.5161 - val_loss: 1.4353 - 2s/epoch - 20ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.5023 - val_loss: 1.4460 - 2s/epoch - 19ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.4874 - val_loss: 1.4916 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.4753 - val_loss: 1.4241 - 2s/epoch - 19ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.4615 - val_loss: 1.6477 - 2s/epoch - 19ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.4542 - val_loss: 1.7094 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.4291 - val_loss: 1.6482 - 2s/epoch - 19ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.4181 - val_loss: 2.0560 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.4067 - val_loss: 1.4592 - 2s/epoch - 20ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.3878 - val_loss: 1.8940 - 2s/epoch - 19ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.3770 - val_loss: 1.6583 - 2s/epoch - 19ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.3595 - val_loss: 1.6494 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.3448 - val_loss: 1.6860 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.3292 - val_loss: 1.6139 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.3163 - val_loss: 1.5636 - 2s/epoch - 19ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.3003 - val_loss: 1.5627 - 2s/epoch - 19ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.2850 - val_loss: 1.6528 - 2s/epoch - 20ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.2699 - val_loss: 1.5634 - 2s/epoch - 20ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.2594 - val_loss: 1.7373 - 2s/epoch - 20ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.2463 - val_loss: 1.7514 - 2s/epoch - 19ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.2302 - val_loss: 1.6930 - 2s/epoch - 19ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.2197 - val_loss: 1.6185 - 2s/epoch - 19ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.2076 - val_loss: 1.7502 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.1959 - val_loss: 1.9069 - 2s/epoch - 19ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.1857 - val_loss: 1.6795 - 2s/epoch - 20ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.1750 - val_loss: 1.7072 - 2s/epoch - 19ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.1616 - val_loss: 1.5910 - 2s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.1544 - val_loss: 1.7097 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.1454 - val_loss: 1.8791 - 2s/epoch - 20ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.1371 - val_loss: 1.8628 - 2s/epoch - 20ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.1308 - val_loss: 1.6743 - 2s/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.1208 - val_loss: 1.8322 - 2s/epoch - 19ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.1149 - val_loss: 1.7337 - 2s/epoch - 20ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.1080 - val_loss: 2.0523 - 2s/epoch - 19ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.1031 - val_loss: 1.7350 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.0959 - val_loss: 1.8032 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.0904 - val_loss: 1.8359 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0871 - val_loss: 1.7054 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0810 - val_loss: 1.7897 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the rmsprop optimizer and elu activation function: 1.789469490892809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9802 - val_loss: 1.0979 - 6s/epoch - 72ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9769 - val_loss: 1.0965 - 2s/epoch - 18ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9764 - val_loss: 1.0973 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 1s - loss: 0.9754 - val_loss: 1.0962 - 1s/epoch - 18ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9752 - val_loss: 1.0983 - 2s/epoch - 18ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9742 - val_loss: 1.0985 - 2s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9729 - val_loss: 1.0975 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9726 - val_loss: 1.0987 - 2s/epoch - 19ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9715 - val_loss: 1.0986 - 2s/epoch - 26ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9702 - val_loss: 1.1025 - 2s/epoch - 19ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9694 - val_loss: 1.1044 - 2s/epoch - 18ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9679 - val_loss: 1.1055 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9661 - val_loss: 1.1224 - 2s/epoch - 19ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9645 - val_loss: 1.1034 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9614 - val_loss: 1.1308 - 2s/epoch - 19ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9587 - val_loss: 1.1333 - 2s/epoch - 19ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9550 - val_loss: 1.1171 - 2s/epoch - 19ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9504 - val_loss: 1.1060 - 2s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9466 - val_loss: 1.1105 - 2s/epoch - 19ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9415 - val_loss: 1.1325 - 2s/epoch - 19ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9341 - val_loss: 1.1317 - 2s/epoch - 19ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9271 - val_loss: 1.1324 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9169 - val_loss: 1.2955 - 2s/epoch - 19ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9083 - val_loss: 1.1945 - 2s/epoch - 19ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.8967 - val_loss: 1.1784 - 2s/epoch - 19ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.8829 - val_loss: 1.2096 - 2s/epoch - 19ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.8688 - val_loss: 1.2647 - 2s/epoch - 19ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.8527 - val_loss: 1.2117 - 2s/epoch - 19ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.8339 - val_loss: 1.2149 - 2s/epoch - 20ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.8161 - val_loss: 1.2827 - 2s/epoch - 20ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.7963 - val_loss: 1.2873 - 2s/epoch - 19ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.7775 - val_loss: 1.2576 - 2s/epoch - 19ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.7555 - val_loss: 1.2633 - 2s/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.7361 - val_loss: 1.4864 - 2s/epoch - 18ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.7159 - val_loss: 1.3869 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.6936 - val_loss: 1.4123 - 2s/epoch - 19ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.6768 - val_loss: 1.2688 - 2s/epoch - 20ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.6588 - val_loss: 1.6671 - 2s/epoch - 21ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.6368 - val_loss: 1.3194 - 2s/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.6208 - val_loss: 1.3482 - 2s/epoch - 19ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.5982 - val_loss: 1.3260 - 2s/epoch - 19ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.5775 - val_loss: 1.4117 - 2s/epoch - 19ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.5555 - val_loss: 1.4130 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.5392 - val_loss: 1.4366 - 2s/epoch - 19ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.5174 - val_loss: 1.4919 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.4949 - val_loss: 1.5179 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.4752 - val_loss: 1.6511 - 2s/epoch - 19ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.4556 - val_loss: 1.5903 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.4350 - val_loss: 1.9024 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.4167 - val_loss: 1.5721 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.4011 - val_loss: 1.7525 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.3799 - val_loss: 1.6206 - 2s/epoch - 19ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.3644 - val_loss: 1.7162 - 2s/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.3427 - val_loss: 1.5621 - 2s/epoch - 20ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.3247 - val_loss: 1.7537 - 2s/epoch - 19ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.3077 - val_loss: 1.7476 - 2s/epoch - 19ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.2947 - val_loss: 1.9513 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.2780 - val_loss: 1.6776 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.2637 - val_loss: 1.6464 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.2480 - val_loss: 1.6531 - 2s/epoch - 19ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.2296 - val_loss: 1.6228 - 2s/epoch - 20ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.2220 - val_loss: 1.7502 - 2s/epoch - 20ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.2056 - val_loss: 1.7816 - 2s/epoch - 19ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.1946 - val_loss: 1.8205 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.1837 - val_loss: 1.7815 - 2s/epoch - 19ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.1737 - val_loss: 1.8765 - 2s/epoch - 19ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.1617 - val_loss: 2.0301 - 2s/epoch - 19ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.1508 - val_loss: 1.6706 - 2s/epoch - 18ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.1432 - val_loss: 1.7401 - 2s/epoch - 19ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.1319 - val_loss: 1.9664 - 2s/epoch - 20ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.1261 - val_loss: 1.7551 - 2s/epoch - 20ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.1178 - val_loss: 1.7645 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.1109 - val_loss: 1.8023 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.1043 - val_loss: 1.7035 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.0968 - val_loss: 1.7371 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.0929 - val_loss: 1.7558 - 2s/epoch - 19ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.0858 - val_loss: 1.8986 - 2s/epoch - 19ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.0833 - val_loss: 1.6951 - 2s/epoch - 20ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.0770 - val_loss: 1.7962 - 2s/epoch - 20ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.0730 - val_loss: 1.8887 - 2s/epoch - 20ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.0683 - val_loss: 1.7739 - 2s/epoch - 20ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.0639 - val_loss: 1.9250 - 2s/epoch - 20ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.0630 - val_loss: 1.7970 - 2s/epoch - 20ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.0583 - val_loss: 1.8531 - 2s/epoch - 19ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.0583 - val_loss: 1.8356 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.0527 - val_loss: 1.7081 - 2s/epoch - 20ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.0511 - val_loss: 1.7606 - 2s/epoch - 19ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.0484 - val_loss: 1.8884 - 2s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.0467 - val_loss: 1.8362 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.0441 - val_loss: 1.7583 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.0430 - val_loss: 1.7456 - 2s/epoch - 19ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.0420 - val_loss: 1.7593 - 2s/epoch - 19ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.0401 - val_loss: 1.7190 - 2s/epoch - 20ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.0393 - val_loss: 1.7603 - 2s/epoch - 21ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.0376 - val_loss: 1.8065 - 2s/epoch - 19ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.0375 - val_loss: 1.7428 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.0340 - val_loss: 1.6770 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.0339 - val_loss: 1.7389 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.0346 - val_loss: 1.7736 - 2s/epoch - 19ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.0311 - val_loss: 1.7437 - 2s/epoch - 19ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the rmsprop optimizer and selu activation function: 1.74372749662868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9761 - val_loss: 1.0968 - 6s/epoch - 75ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0973 - 2s/epoch - 19ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9759 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0966 - 2s/epoch - 20ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0956 - 2s/epoch - 19ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0955 - 2s/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 21ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0970 - 2s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 21ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0965 - 2s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0965 - 2s/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 21ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0968 - 2s/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0971 - 2s/epoch - 21ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0964 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0967 - 2s/epoch - 19ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0966 - 2s/epoch - 20ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 21ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0956 - 2s/epoch - 21ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0965 - 2s/epoch - 19ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 21ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 21ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 19ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 21ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 20ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 21ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0957 - 2s/epoch - 20ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0957 - 2s/epoch - 20ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.9759 - val_loss: 1.0965 - 2s/epoch - 19ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0965 - 2s/epoch - 20ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 21ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0964 - 2s/epoch - 19ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 19ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 20ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0959 - 2s/epoch - 19ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 19ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0960 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0958 - 2s/epoch - 19ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 20ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0962 - 2s/epoch - 20ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the rmsprop optimizer and softmax activation function: 1.0961718970534142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 - 6s - loss: 0.9762 - val_loss: 1.0969 - 6s/epoch - 75ms/step\n",
            "Epoch 2/100\n",
            "82/82 - 2s - loss: 0.9761 - val_loss: 1.0965 - 2s/epoch - 19ms/step\n",
            "Epoch 3/100\n",
            "82/82 - 2s - loss: 0.9760 - val_loss: 1.0963 - 2s/epoch - 21ms/step\n",
            "Epoch 4/100\n",
            "82/82 - 2s - loss: 0.9758 - val_loss: 1.0961 - 2s/epoch - 20ms/step\n",
            "Epoch 5/100\n",
            "82/82 - 2s - loss: 0.9756 - val_loss: 1.0981 - 2s/epoch - 20ms/step\n",
            "Epoch 6/100\n",
            "82/82 - 2s - loss: 0.9755 - val_loss: 1.0966 - 2s/epoch - 20ms/step\n",
            "Epoch 7/100\n",
            "82/82 - 2s - loss: 0.9752 - val_loss: 1.0956 - 2s/epoch - 20ms/step\n",
            "Epoch 8/100\n",
            "82/82 - 2s - loss: 0.9749 - val_loss: 1.0991 - 2s/epoch - 20ms/step\n",
            "Epoch 9/100\n",
            "82/82 - 2s - loss: 0.9744 - val_loss: 1.0966 - 2s/epoch - 20ms/step\n",
            "Epoch 10/100\n",
            "82/82 - 2s - loss: 0.9738 - val_loss: 1.0967 - 2s/epoch - 21ms/step\n",
            "Epoch 11/100\n",
            "82/82 - 2s - loss: 0.9730 - val_loss: 1.1024 - 2s/epoch - 21ms/step\n",
            "Epoch 12/100\n",
            "82/82 - 2s - loss: 0.9720 - val_loss: 1.0976 - 2s/epoch - 20ms/step\n",
            "Epoch 13/100\n",
            "82/82 - 2s - loss: 0.9708 - val_loss: 1.0986 - 2s/epoch - 20ms/step\n",
            "Epoch 14/100\n",
            "82/82 - 2s - loss: 0.9707 - val_loss: 1.1052 - 2s/epoch - 20ms/step\n",
            "Epoch 15/100\n",
            "82/82 - 2s - loss: 0.9702 - val_loss: 1.1070 - 2s/epoch - 20ms/step\n",
            "Epoch 16/100\n",
            "82/82 - 2s - loss: 0.9690 - val_loss: 1.1166 - 2s/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "82/82 - 2s - loss: 0.9685 - val_loss: 1.1075 - 2s/epoch - 21ms/step\n",
            "Epoch 18/100\n",
            "82/82 - 2s - loss: 0.9669 - val_loss: 1.1033 - 2s/epoch - 21ms/step\n",
            "Epoch 19/100\n",
            "82/82 - 2s - loss: 0.9663 - val_loss: 1.1075 - 2s/epoch - 22ms/step\n",
            "Epoch 20/100\n",
            "82/82 - 2s - loss: 0.9653 - val_loss: 1.1036 - 2s/epoch - 20ms/step\n",
            "Epoch 21/100\n",
            "82/82 - 2s - loss: 0.9650 - val_loss: 1.1155 - 2s/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "82/82 - 2s - loss: 0.9628 - val_loss: 1.1046 - 2s/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "82/82 - 2s - loss: 0.9622 - val_loss: 1.1156 - 2s/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "82/82 - 2s - loss: 0.9613 - val_loss: 1.1212 - 2s/epoch - 21ms/step\n",
            "Epoch 25/100\n",
            "82/82 - 2s - loss: 0.9583 - val_loss: 1.1132 - 2s/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "82/82 - 2s - loss: 0.9568 - val_loss: 1.1096 - 2s/epoch - 21ms/step\n",
            "Epoch 27/100\n",
            "82/82 - 2s - loss: 0.9564 - val_loss: 1.1113 - 2s/epoch - 21ms/step\n",
            "Epoch 28/100\n",
            "82/82 - 2s - loss: 0.9522 - val_loss: 1.1197 - 2s/epoch - 21ms/step\n",
            "Epoch 29/100\n",
            "82/82 - 2s - loss: 0.9503 - val_loss: 1.1136 - 2s/epoch - 21ms/step\n",
            "Epoch 30/100\n",
            "82/82 - 2s - loss: 0.9491 - val_loss: 1.1154 - 2s/epoch - 21ms/step\n",
            "Epoch 31/100\n",
            "82/82 - 2s - loss: 0.9462 - val_loss: 1.1279 - 2s/epoch - 20ms/step\n",
            "Epoch 32/100\n",
            "82/82 - 2s - loss: 0.9415 - val_loss: 1.1195 - 2s/epoch - 19ms/step\n",
            "Epoch 33/100\n",
            "82/82 - 2s - loss: 0.9388 - val_loss: 1.1506 - 2s/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "82/82 - 2s - loss: 0.9357 - val_loss: 1.1186 - 2s/epoch - 20ms/step\n",
            "Epoch 35/100\n",
            "82/82 - 2s - loss: 0.9321 - val_loss: 1.1627 - 2s/epoch - 19ms/step\n",
            "Epoch 36/100\n",
            "82/82 - 2s - loss: 0.9283 - val_loss: 1.1141 - 2s/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "82/82 - 2s - loss: 0.9230 - val_loss: 1.1286 - 2s/epoch - 20ms/step\n",
            "Epoch 38/100\n",
            "82/82 - 2s - loss: 0.9188 - val_loss: 1.1534 - 2s/epoch - 20ms/step\n",
            "Epoch 39/100\n",
            "82/82 - 2s - loss: 0.9113 - val_loss: 1.1271 - 2s/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "82/82 - 2s - loss: 0.9053 - val_loss: 1.1425 - 2s/epoch - 21ms/step\n",
            "Epoch 41/100\n",
            "82/82 - 2s - loss: 0.9005 - val_loss: 1.1587 - 2s/epoch - 21ms/step\n",
            "Epoch 42/100\n",
            "82/82 - 2s - loss: 0.8911 - val_loss: 1.1963 - 2s/epoch - 21ms/step\n",
            "Epoch 43/100\n",
            "82/82 - 2s - loss: 0.8838 - val_loss: 1.2024 - 2s/epoch - 21ms/step\n",
            "Epoch 44/100\n",
            "82/82 - 2s - loss: 0.8764 - val_loss: 1.1653 - 2s/epoch - 20ms/step\n",
            "Epoch 45/100\n",
            "82/82 - 2s - loss: 0.8660 - val_loss: 1.1326 - 2s/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "82/82 - 2s - loss: 0.8563 - val_loss: 1.1770 - 2s/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "82/82 - 2s - loss: 0.8492 - val_loss: 1.1676 - 2s/epoch - 21ms/step\n",
            "Epoch 48/100\n",
            "82/82 - 2s - loss: 0.8383 - val_loss: 1.2024 - 2s/epoch - 21ms/step\n",
            "Epoch 49/100\n",
            "82/82 - 2s - loss: 0.8289 - val_loss: 1.2514 - 2s/epoch - 22ms/step\n",
            "Epoch 50/100\n",
            "82/82 - 2s - loss: 0.8174 - val_loss: 1.3039 - 2s/epoch - 21ms/step\n",
            "Epoch 51/100\n",
            "82/82 - 2s - loss: 0.8105 - val_loss: 1.1744 - 2s/epoch - 21ms/step\n",
            "Epoch 52/100\n",
            "82/82 - 2s - loss: 0.8000 - val_loss: 1.1897 - 2s/epoch - 21ms/step\n",
            "Epoch 53/100\n",
            "82/82 - 2s - loss: 0.7879 - val_loss: 1.1894 - 2s/epoch - 22ms/step\n",
            "Epoch 54/100\n",
            "82/82 - 2s - loss: 0.7748 - val_loss: 1.2007 - 2s/epoch - 22ms/step\n",
            "Epoch 55/100\n",
            "82/82 - 2s - loss: 0.7682 - val_loss: 1.4818 - 2s/epoch - 23ms/step\n",
            "Epoch 56/100\n",
            "82/82 - 2s - loss: 0.7622 - val_loss: 1.1682 - 2s/epoch - 22ms/step\n",
            "Epoch 57/100\n",
            "82/82 - 2s - loss: 0.7435 - val_loss: 1.2382 - 2s/epoch - 21ms/step\n",
            "Epoch 58/100\n",
            "82/82 - 2s - loss: 0.7404 - val_loss: 1.2089 - 2s/epoch - 20ms/step\n",
            "Epoch 59/100\n",
            "82/82 - 2s - loss: 0.7238 - val_loss: 1.1925 - 2s/epoch - 21ms/step\n",
            "Epoch 60/100\n",
            "82/82 - 2s - loss: 0.7145 - val_loss: 1.2744 - 2s/epoch - 20ms/step\n",
            "Epoch 61/100\n",
            "82/82 - 2s - loss: 0.7074 - val_loss: 1.2018 - 2s/epoch - 20ms/step\n",
            "Epoch 62/100\n",
            "82/82 - 2s - loss: 0.6897 - val_loss: 1.4064 - 2s/epoch - 20ms/step\n",
            "Epoch 63/100\n",
            "82/82 - 2s - loss: 0.6795 - val_loss: 1.3114 - 2s/epoch - 20ms/step\n",
            "Epoch 64/100\n",
            "82/82 - 2s - loss: 0.6640 - val_loss: 1.3449 - 2s/epoch - 21ms/step\n",
            "Epoch 65/100\n",
            "82/82 - 2s - loss: 0.6616 - val_loss: 1.3055 - 2s/epoch - 20ms/step\n",
            "Epoch 66/100\n",
            "82/82 - 2s - loss: 0.6463 - val_loss: 1.3481 - 2s/epoch - 20ms/step\n",
            "Epoch 67/100\n",
            "82/82 - 2s - loss: 0.6300 - val_loss: 1.2781 - 2s/epoch - 20ms/step\n",
            "Epoch 68/100\n",
            "82/82 - 2s - loss: 0.6232 - val_loss: 1.2515 - 2s/epoch - 20ms/step\n",
            "Epoch 69/100\n",
            "82/82 - 2s - loss: 0.6077 - val_loss: 1.3688 - 2s/epoch - 20ms/step\n",
            "Epoch 70/100\n",
            "82/82 - 2s - loss: 0.6011 - val_loss: 1.9933 - 2s/epoch - 20ms/step\n",
            "Epoch 71/100\n",
            "82/82 - 2s - loss: 0.5967 - val_loss: 1.2696 - 2s/epoch - 21ms/step\n",
            "Epoch 72/100\n",
            "82/82 - 2s - loss: 0.5794 - val_loss: 1.2944 - 2s/epoch - 20ms/step\n",
            "Epoch 73/100\n",
            "82/82 - 2s - loss: 0.5690 - val_loss: 1.3402 - 2s/epoch - 20ms/step\n",
            "Epoch 74/100\n",
            "82/82 - 2s - loss: 0.5533 - val_loss: 1.3607 - 2s/epoch - 20ms/step\n",
            "Epoch 75/100\n",
            "82/82 - 2s - loss: 0.5444 - val_loss: 1.2945 - 2s/epoch - 19ms/step\n",
            "Epoch 76/100\n",
            "82/82 - 2s - loss: 0.5313 - val_loss: 1.7610 - 2s/epoch - 20ms/step\n",
            "Epoch 77/100\n",
            "82/82 - 2s - loss: 0.5285 - val_loss: 1.3309 - 2s/epoch - 20ms/step\n",
            "Epoch 78/100\n",
            "82/82 - 2s - loss: 0.5063 - val_loss: 1.7114 - 2s/epoch - 21ms/step\n",
            "Epoch 79/100\n",
            "82/82 - 2s - loss: 0.5039 - val_loss: 1.4206 - 2s/epoch - 21ms/step\n",
            "Epoch 80/100\n",
            "82/82 - 2s - loss: 0.4900 - val_loss: 1.3634 - 2s/epoch - 20ms/step\n",
            "Epoch 81/100\n",
            "82/82 - 2s - loss: 0.4817 - val_loss: 1.3902 - 2s/epoch - 20ms/step\n",
            "Epoch 82/100\n",
            "82/82 - 2s - loss: 0.4761 - val_loss: 1.4017 - 2s/epoch - 20ms/step\n",
            "Epoch 83/100\n",
            "82/82 - 2s - loss: 0.4648 - val_loss: 1.6010 - 2s/epoch - 20ms/step\n",
            "Epoch 84/100\n",
            "82/82 - 2s - loss: 0.4529 - val_loss: 1.4267 - 2s/epoch - 20ms/step\n",
            "Epoch 85/100\n",
            "82/82 - 2s - loss: 0.4410 - val_loss: 1.4558 - 2s/epoch - 20ms/step\n",
            "Epoch 86/100\n",
            "82/82 - 2s - loss: 0.4334 - val_loss: 1.4579 - 2s/epoch - 21ms/step\n",
            "Epoch 87/100\n",
            "82/82 - 2s - loss: 0.4218 - val_loss: 1.4910 - 2s/epoch - 20ms/step\n",
            "Epoch 88/100\n",
            "82/82 - 2s - loss: 0.4069 - val_loss: 1.4707 - 2s/epoch - 20ms/step\n",
            "Epoch 89/100\n",
            "82/82 - 2s - loss: 0.4007 - val_loss: 1.4167 - 2s/epoch - 21ms/step\n",
            "Epoch 90/100\n",
            "82/82 - 2s - loss: 0.3881 - val_loss: 1.3721 - 2s/epoch - 20ms/step\n",
            "Epoch 91/100\n",
            "82/82 - 2s - loss: 0.3787 - val_loss: 1.3543 - 2s/epoch - 21ms/step\n",
            "Epoch 92/100\n",
            "82/82 - 2s - loss: 0.3673 - val_loss: 1.6467 - 2s/epoch - 20ms/step\n",
            "Epoch 93/100\n",
            "82/82 - 2s - loss: 0.3570 - val_loss: 1.4857 - 2s/epoch - 20ms/step\n",
            "Epoch 94/100\n",
            "82/82 - 2s - loss: 0.3468 - val_loss: 1.4849 - 2s/epoch - 20ms/step\n",
            "Epoch 95/100\n",
            "82/82 - 2s - loss: 0.3346 - val_loss: 1.4575 - 2s/epoch - 20ms/step\n",
            "Epoch 96/100\n",
            "82/82 - 2s - loss: 0.3254 - val_loss: 1.6564 - 2s/epoch - 19ms/step\n",
            "Epoch 97/100\n",
            "82/82 - 2s - loss: 0.3141 - val_loss: 1.6211 - 2s/epoch - 19ms/step\n",
            "Epoch 98/100\n",
            "82/82 - 2s - loss: 0.3024 - val_loss: 1.6156 - 2s/epoch - 20ms/step\n",
            "Epoch 99/100\n",
            "82/82 - 2s - loss: 0.2930 - val_loss: 1.6673 - 2s/epoch - 20ms/step\n",
            "Epoch 100/100\n",
            "82/82 - 2s - loss: 0.2834 - val_loss: 1.5749 - 2s/epoch - 20ms/step\n",
            "163/163 [==============================] - 1s 3ms/step\n",
            "Average MSE for the rmsprop optimizer and swish activation function: 1.574620664128314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mse_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKSpLkyEJ4QK",
        "outputId": "1662cf74-8b1e-4373-b3a5-5741f09db1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.696575788400437, 1.4836267901570335, 1.7022734607464867, 1.708962638406095, 1.5919721724509737, 1.0961801494468337, 1.726414302468425, 1.5745033534170478, 1.0960931381453745, 2.022044649278073, 1.789469490892809, 1.74372749662868, 1.0961718970534142, 1.574620664128314]\n"
          ]
        }
      ]
    }
  ]
}